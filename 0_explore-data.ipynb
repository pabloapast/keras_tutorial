{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "805a97911f01abb36ff8414d8d6aec9293e4fb85"
   },
   "source": [
    " <h1><center><font size=\"6\">CNN with Keras for Fashion MNIST</font></center></h1>\n",
    "\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-card.png\" width=\"400\"></img>\n",
    "\n",
    "\n",
    "# <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>Introduction</a>  \n",
    "- <a href='#2'>Load packages</a>  \n",
    "- <a href='#3'>Read the data</a>  \n",
    "- <a href='#4'>Data exploration</a>\n",
    "    - <a href='#41'>Class distribution</a>\n",
    "    - <a href='#42'>Images samples</a>\n",
    "- <a href='#5'>Model</a>  \n",
    "    - <a href='#51'>Prepare the model</a>  \n",
    "    - <a href='#52'>Train the model</a>  \n",
    "    - <a href='#53'>Test prediction accuracy</a>   \n",
    "    - <a href='#54'>Validation accuracy and loss</a>   \n",
    "    - <a href='#55'>Add Dropout layers to the model</a>  \n",
    "    - <a href='#56'>Re-train the model</a>   \n",
    "    - <a href='#57'>Check validation accuracy and loss with the new model</a>    \n",
    "    - <a href='#58'>Prediction accuracy with the new model </a>   \n",
    "- <a href='#6'>Visualize the classified images</a>  \n",
    "    - <a href='#61'>Correctly classified images</a>   \n",
    "    - <a href='#62'>Incorrectly classified images</a>   \n",
    "- <a href='#8'>References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b1c16628c2f62a18e1dc2068e1d67d7003922b1"
   },
   "source": [
    "# <a id=\"1\">Introduction</a>  \n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "\n",
    "## Content\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.   \n",
    "\n",
    "Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a708dc52b2e5990e2247ed573d50d0f6933b730"
   },
   "source": [
    "# <a id=\"2\">Load packages</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2defa674e4e6d0e7371df92e7d1f388fc5c14bb6"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e17fd2539412442ddb3ecacf84366ddd62faf836"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7a44bfc7a28df7026241c4a7e047298446f1554"
   },
   "outputs": [],
   "source": [
    "# Some constants\n",
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "NUM_CLASSES = 10\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 2018\n",
    "#Model\n",
    "NO_EPOCHS = 50\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f49d65b4af77e87ab34b6854850619911cff1e6d"
   },
   "source": [
    "# <a id=\"3\">Read the data</a>\n",
    "\n",
    "There are 10 different classes of images, as following: \n",
    "\n",
    "* **0**: **T-shirt/top**;   \n",
    "* **1**: **Trouser**;   \n",
    "* **2**: **Pullover**;   \n",
    "* **3**: **Dress**;\n",
    "* **4**: **Coat**;\n",
    "* **5**: **Sandal**;\n",
    "* **6**: **Shirt**;\n",
    "* **7**: **Sneaker**;\n",
    "* **8**: **Bag**;\n",
    "* **9**: **Ankle boot**.\n",
    "\n",
    "Image dimmensions are **28**x**28**.   \n",
    "\n",
    "The train set and test set are given in two separate sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9c3148fda056ecc88570b302f5185064d5e9fc8"
   },
   "outputs": [],
   "source": [
    "(x_train_data, y_train_data), (x_test_data, y_test_data) = fashion_mnist.load_data()\n",
    "\n",
    "# Create a dictionary for each type of label \n",
    "LABELS = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "290f8f38b2f64dfd1bd3432eb1e9a101dbbaf4e5"
   },
   "source": [
    "# <a id=\"4\">Data exploration</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8891ae7996aa2ae5bc1c025661a77ae91c2fdfb"
   },
   "source": [
    "![](http://)The dimmension of the original  train,  test set are as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a133496cefc53baa56b9a5eec93bfd064ea6360d"
   },
   "outputs": [],
   "source": [
    "print(\"Fashion MNIST x_train shape: {}\".format(x_train_data.shape))\n",
    "print(\"Fashion MNIST y_train shape: {}\".format(y_train_data.shape))\n",
    "print(\"Fashion MNIST x_test shape: {}\".format(x_test_data.shape))\n",
    "print(\"Fashion MNIST y_test shape: {}\".format(y_test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc317fbf40c9b2838f8091e745a64e060a7affc0"
   },
   "source": [
    "## <a id=\"41\">Class distribution</a>\n",
    "\n",
    "Let's see how many number of images are in each class. We start with the train set.\n",
    "\n",
    "### Train set images class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da948eb587daf81160a4794a36662f8872c882a4"
   },
   "outputs": [],
   "source": [
    "def get_classes_distribution(y_data):\n",
    "    # Get the count for each label\n",
    "    y = np.bincount(y_data)\n",
    "    ii = np.nonzero(y)[0]\n",
    "    label_counts = zip(ii, y[ii])\n",
    "\n",
    "    # Get total number of samples\n",
    "    total_samples = len(y_data)\n",
    "\n",
    "    # Count the number of items in each class\n",
    "    for label, count in label_counts:\n",
    "        class_name = LABELS[label]\n",
    "        percent = (count / total_samples) * 100\n",
    "        print(\"{:<15s}:  {} or {:.2f}%\".format(class_name, count, percent))\n",
    "        \n",
    "    return label_counts\n",
    "\n",
    "train_label_counts = get_classes_distribution(y_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc41d889d3ad6352994cdf8a76a78ed0d22ec141"
   },
   "source": [
    "The classes are equaly distributed in the train set (10% each). Let's check the same for the test set.    \n",
    "Let's also plot the class distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ac8f6fde6bd78553f08469093cebc0e124a5210"
   },
   "outputs": [],
   "source": [
    "def plot_label_per_class(y_data):\n",
    "    \n",
    "    classes = sorted(np.unique(y_data))\n",
    "    f, ax = plt.subplots(1,1, figsize=(12, 4))\n",
    "    g = sns.countplot(y_data, order=classes)\n",
    "    g.set_title(\"Number of labels for each class\")\n",
    "    \n",
    "    for p, label in zip(g.patches, classes):\n",
    "        g.annotate(LABELS[label], (p.get_x(), p.get_height() + 0.2))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "plot_label_per_class(y_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7c3328ce859d1809ce916bba73bc57b2d580963"
   },
   "source": [
    "### Test set images class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2581093ff1268ae9487fe83b383c2d4be4657000"
   },
   "outputs": [],
   "source": [
    "get_classes_distribution(y_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fffa6f5248eb037b47a84e1e1ee889ee3470a1d4"
   },
   "source": [
    "Also in the test set the 10 classes are equaly distributed (10% each).  \n",
    "\n",
    "Lets' also plot the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d770b2cde8f32b83a67da02eeacd17f01904ddd"
   },
   "outputs": [],
   "source": [
    "plot_label_per_class(y_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "588beb3c38b5f5a0b41ca0699426a1477efb8412"
   },
   "source": [
    "## <a id=\"42\">Sample images</a>\n",
    "\n",
    "### Train set images\n",
    "\n",
    "Let's plot some samples for the images.   \n",
    "We add labels to the train set images, with the corresponding fashion item category.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62fd41c12740f184ec160d692b3289d4457297d6"
   },
   "outputs": [],
   "source": [
    "def sample_images_data(x_data, y_data):\n",
    "    # An empty list to collect some samples\n",
    "    sample_images = []\n",
    "    sample_labels = []\n",
    "\n",
    "    # Iterate over the keys of the labels dictionary defined in the above cell\n",
    "    for k in LABELS.keys():\n",
    "        # Get four samples for each category\n",
    "        samples = np.where(y_data == k)[0][:4]\n",
    "        # Append the samples to the samples list\n",
    "        for s in samples:\n",
    "            img = x_data[s]\n",
    "            sample_images.append(img)\n",
    "            sample_labels.append(y_data[s])\n",
    "\n",
    "    print(\"Total number of sample images to plot: \", len(sample_images))\n",
    "    return sample_images, sample_labels\n",
    "\n",
    "train_sample_images, train_sample_labels = sample_images_data(x_train_data, y_train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5c80cef30985bb5ab0ee48d4fc9891660c2a92f"
   },
   "source": [
    "Let's now plot the images.   \n",
    "The labels are shown above each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f4f27f5143bdd834302a2c43cdb1d68d2a131a9"
   },
   "outputs": [],
   "source": [
    "def plot_sample_images(data_sample_images, data_sample_labels, cmap=\"gray\"):\n",
    "    # Plot the sample images now\n",
    "    f, ax = plt.subplots(5, 8, figsize=(16, 10))\n",
    "\n",
    "    for i, img in enumerate(data_sample_images):\n",
    "        ax[i//8, i%8].imshow(img, cmap=cmap)\n",
    "        ax[i//8, i%8].axis('off')\n",
    "        ax[i//8, i%8].set_title(LABELS[data_sample_labels[i]])\n",
    "    plt.show()    \n",
    "    \n",
    "plot_sample_images(train_sample_images, train_sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd30352b2674a20eca5e792d7c186cdcbab25461"
   },
   "source": [
    "### Test set images\n",
    "\n",
    "Let's plot now a selection of the test set images.  \n",
    "Labels are as well added (they are known).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "616df96bfae0e8065c206e6dfec2847d5d42125d"
   },
   "outputs": [],
   "source": [
    "test_sample_images, test_sample_labels = sample_images_data(x_test_data, y_test_data)\n",
    "plot_sample_images(test_sample_images, test_sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "273c79c7470c49fe7a546dd7148e0536be2dee19"
   },
   "source": [
    "# <a id=\"5\">Model</a>\n",
    "\n",
    "We start with preparing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10b920b2ffc5de4a3ddebe494966d90cca91ee95"
   },
   "source": [
    "## <a id=\"51\">Prepare the model</a>\n",
    "\n",
    "## Data preprocessing\n",
    "\n",
    "First we will do a data preprocessing to prepare for the model.\n",
    "\n",
    "We save label (target) feature as a separate vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db4c308b9fb334a54b4c055b00d2a1fbcf77ab96"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(x_data, y_data):\n",
    "    out_y = to_categorical(y_data, len(np.unique(y_data)))\n",
    "    num_images = x_data.shape[0]\n",
    "    x_shaped_array = np.expand_dims(x_data, axis=-1)\n",
    "    out_x = x_shaped_array / 255.\n",
    "    \n",
    "    return out_x, out_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d3cafa55173d40cd9a42df63d4919f03b264c09"
   },
   "source": [
    "We process both the train_data and the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "454d7a8fdca4bdbefc04a9d796de04b6af4a1767"
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "X, y = data_preprocessing(x_train_data, y_train_data)\n",
    "X_test, y_test = data_preprocessing(x_test_data, y_test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e25c569f0a0e817ca0462f3e3ea2f50feb480b0"
   },
   "source": [
    "## Split train in train and validation set\n",
    "\n",
    "We further split the train set in train and validation set. The validation set will be 20% from the original train set, therefore the split will be train/validation of 0.8/0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36eb910dd0868a227a73c9759d6aee0a47ba2b1e"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Fashion MNIST X train  -  rows: {}  columns: {}\".format(X_train.shape[0], X_train.shape[1:4]))\n",
    "print(\"Fashion MNIST X valid  -  rows: {}  columns: {}\".format(X_val.shape[0], X_val.shape[1:4]))\n",
    "print(\"Fashion MNIST X test   -  rows: {}  columns: {}\".format(X_test.shape[0], X_test.shape[1:4]))\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"Fashion MNIST y train  -  rows: {}  columns: {}\".format(y_train.shape[0], y_train.shape[1]))\n",
    "print(\"Fashion MNIST y valid  -  rows: {}  columns: {}\".format(y_val.shape[0], y_val.shape[1]))\n",
    "print(\"Fashion MNIST y test   -  rows: {}  columns: {}\".format(y_test.shape[0], y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bc44b14e07efcd3dda90deaac6884b07285b484"
   },
   "source": [
    "Let's check the class inbalance for the rsulted training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classes_distribution(np.argmax(y_train, axis=1))\n",
    "plot_label_per_class(np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07bfe3d5d50b985788a28e546473fd885d96dcef"
   },
   "source": [
    "And, as well, for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af3b3d31c42637235bc07b700db121e37e156afc"
   },
   "outputs": [],
   "source": [
    "get_classes_distribution(np.argmax(y_val, axis=1))\n",
    "plot_label_per_class(np.argmax(y_val, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd9405b5a3fe0c7bd5bebe0616190a8cf26d2811"
   },
   "source": [
    "## <a id=\"52\">Train the model</a>\n",
    "\n",
    "### Build the model   \n",
    "\n",
    "\n",
    "\n",
    "We will use a **Sequential** model.\n",
    "* The **Sequential** model is a linear stack of layers. It can be first initialized and then we add layers using **add** method or we can add all layers at init stage. The layers added are as follows:\n",
    "\n",
    "* **Conv2D** is a 2D Convolutional layer (i.e. spatial convolution over images). The parameters used are:\n",
    " * filters - the number of filters (Kernels) used with this layer; here filters = 32;\n",
    " * kernel_size - the dimmension of the Kernel: (3 x 3);\n",
    " * activation - is the activation function used, in this case `relu`;\n",
    " * kernel_initializer - the function used for initializing the kernel;\n",
    " * input_shape - is the shape of the image presented to the CNN: in our case is 28 x 28\n",
    " The input and output of the **Conv2D** is a 4D tensor.\n",
    " \n",
    "* **MaxPooling2D** is a Max pooling operation for spatial data. Parameters used here are:\n",
    " * *pool_size*, in this case (2,2), representing the factors by which to downscale in both directions;\n",
    " \n",
    "* **Conv2D** with the following parameters:\n",
    " * filters: 64;\n",
    " * kernel_size : (3 x 3);\n",
    " * activation : `relu`;\n",
    " \n",
    "* **MaxPooling2D** with parameter:\n",
    " * *pool_size* : (2,2);\n",
    "\n",
    "* **Conv2D** with the following parameters:\n",
    " * filters: 128;\n",
    " * kernel_size : (3 x 3);\n",
    " * activation : `relu`;\n",
    " \n",
    "* **Flatten**. This layer Flattens the input. Does not affect the batch size. It is used without parameters;\n",
    "\n",
    "* **Dense**. This layer is a regular fully-connected NN layer. It is used without parameters;\n",
    " * units - this is a positive integer, with the meaning: dimensionality of the output space; in this case is: 128;\n",
    " * activation - activation function : `relu`;\n",
    " \n",
    "* **Dense**. This is the final layer (fully connected). It is used with the parameters:\n",
    " * units: the number of classes (in our case 10);\n",
    " * activation : `softmax`; for this final layer it is used `softmax` activation (standard for multiclass classification)\n",
    " \n",
    "\n",
    "Then we compile the model, specifying as well the following parameters:\n",
    "* *loss*;\n",
    "* *optimizer*;\n",
    "* *metrics*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e31836cd5ec9d86340485404b8f613d1f574aca4"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecb450d70539a62fb310bb7ed44849d2d01481ee"
   },
   "source": [
    "### Inspect the model\n",
    "\n",
    "Let's check the model we initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4b923b11ceaf4a97677f8e24265e3e97ae1653b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47062fcbe61fdc131bdc369428415c483167d046"
   },
   "source": [
    "Let's also plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9863ccbdc1a3f9d03fc6f3dbbd3f2713995d03e"
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68a2e932241f29e52a3150b3fcf3fe9c21243be2"
   },
   "source": [
    "### Run the model\n",
    "\n",
    "We run the model with the training set. We are also using the validation set (a subset from the orginal training set) for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "400494b7e0525069175625422e8c300bd7b41c51",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=NO_EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8699df44bc0a95f1a43a201d3dd566746d87173f"
   },
   "source": [
    "## <a id=\"53\">Test prediction accuracy</a>\n",
    "\n",
    "We calculate the test loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9e2bb7f25b02d491e34dd0d6d05943e287ae369"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d779b0e47b8263370031c292a231b69decad374"
   },
   "source": [
    "We evaluated the model accuracy based on the predicted values for the test set.  Let's check the validation value during training.\n",
    "\n",
    "## <a id=\"53\">Validation accuracy and loss</a>\n",
    "\n",
    "Let's plot the train and validation accuracy and loss, from the train history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6122e4d5c504efcc6f05ca65652cdf307c706049"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['acc']\n",
    "    val_acc = hist['val_acc']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    f, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "    ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
    "    ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy_and_loss(train_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "678f32a0980699b8aa41a3f98840bcc1eabb2aa8"
   },
   "source": [
    "The validation accuracy does not improve after few epochs and the validation loss is increasing after few epochs. This confirms our assumption that the model is overfitted. We will try to improve the model by adding Dropout layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c026022d95d3afefc3e2cf47050c3db5f800ee1"
   },
   "source": [
    "## <a id=\"55\">Add Dropout layers to the model</a>\n",
    "\n",
    "We add several Dropout layers to the model, to help avoiding overfitting.    \n",
    "Dropout is helping avoid overfitting in several ways, as explained in <a href='#8'>[6]</a> and <a href='#8'>[7]</a>.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6aff87cd33a993a60d701c35026ce8ea19d8665a"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46811947e60224235b1ffaed48e7367b3ba68833"
   },
   "source": [
    "## <a id=\"56\">Re-train the model</a>\n",
    "\n",
    "Let's inspect first the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "594c8f00280db3fd6d4719791326d73c4769117d"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab0eb83773ab435204faef8c88b609a29feb635e"
   },
   "source": [
    "Let's also plot the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6abc11f358fb81d2655f80bea7762546b18dee82"
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99a964cc1478f1a8583e803ad7eeb35aadd15995"
   },
   "source": [
    "And now let's run the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83029bfb27f99fb6be2ecedc1bd256c0e861456c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=NO_EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "676e1c4a3a64db55d6f0e8498f9c59e0e6182931"
   },
   "source": [
    "## <a id=\"57\">Prediction accuracy with the new model</a>\n",
    "\n",
    "Let's re-evaluate the prediction accuracy with the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b3940059502bfb6303a85a2cee1095b45304491"
   },
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(train_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f201d6925f70ad2420b3ee7e3a204cdc77f86723"
   },
   "source": [
    "After adding the Dropout layers, the validation accuracy and validation loss are much better. Let's check now the prediction for the test set.\n",
    "\n",
    "\n",
    "## <a id=\"58\">Prediction accuracy with the new model</a>\n",
    "\n",
    "Let's re-evaluate the test prediction accuracy with the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8e9293e99e34010bd456af7435c4cc7ccebdefd"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e519f82cc29b0dd8c5145d612da3eb496e2b321d"
   },
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5989dd811570fe73b1f6b0715b06c428e578669"
   },
   "outputs": [],
   "source": [
    "p = predicted_classes\n",
    "y = y_test_data\n",
    "correct = np.nonzero(p == y)[0]\n",
    "incorrect = np.nonzero(p != y)[0]\n",
    "\n",
    "print(\"Correct predicted classes:\", correct.shape[0])\n",
    "print(\"Incorrect predicted classes:\", incorrect.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc3bfd05450aaee55c9e5edc7fb84d884c1d3e0b"
   },
   "outputs": [],
   "source": [
    "target_names = [\"Class {} ({}) :\".format(i, LABELS[i]) for i in range(NUM_CLASSES)]\n",
    "print(classification_report(y_test_data, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b0b88588bd3afed148a3c696d997aea4a6c564a"
   },
   "source": [
    "Let's also inspect some of the images. We created two subsets of the predicted images set, correctly and incorrectly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "614afbc7ed760856cf9b47f879334902d1b6545b"
   },
   "source": [
    "# <a id=\"6\">Visualize classified images</a>\n",
    "\n",
    "## <a id=\"61\">Correctly classified images</a>\n",
    "\n",
    "\n",
    "We visualize few images correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e64edf6e7ae3146eafe8da01f4dbc4e05c8bc1ce"
   },
   "outputs": [],
   "source": [
    "def plot_predicted_images(predictions, data_index, x_data, y_data, size=16, cmap=\"gray\"):\n",
    "    # Plot the sample images now\n",
    "    f, ax = plt.subplots(4, 4, figsize=(15, 15))\n",
    "\n",
    "    for i, indx in enumerate(np.random.choice(data_index, size=size, replace=False)):\n",
    "        ax[i//4, i%4].imshow(x_data[indx].reshape(IMG_ROWS,IMG_COLS), cmap=cmap)\n",
    "        ax[i//4, i%4].axis('off')\n",
    "        ax[i//4, i%4].set_title(\"True:{}  Pred:{}\".format(LABELS[y_data[indx]], LABELS[predicted_classes[indx]]))\n",
    "    plt.show()    \n",
    "    \n",
    "plot_predicted_images(predicted_classes, correct, x_test_data, y_test_data, cmap=\"Greens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c7bb1b300a4530d2fa418eb56258a54587e3b90"
   },
   "source": [
    "## <a id=\"62\">Incorrectly classified images</a>\n",
    "\n",
    "Let's see also few images incorrectly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18b2843f6f8542cd95d0847617e84e959996341b"
   },
   "outputs": [],
   "source": [
    "plot_predicted_images(predicted_classes, incorrect, x_test_data, y_test_data, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b45e3422fb9507da66ce7af67a97b54e7fa7683"
   },
   "source": [
    "# <a id=\"8\">References</a>\n",
    "\n",
    "Original source: https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist/notebook\n",
    "\n",
    "[1] Fashion MNIST, An MNIST-like dataset of 70,000 28x28 labeled fashion images, https://www.kaggle.com/zalando-research/fashionmnist  \n",
    "[2] DanB, CollinMoris, Deep Learning From Scratch, https://www.kaggle.com/dansbecker/deep-learning-from-scratch  \n",
    "[3] DanB, Dropout and Strides for Larger Models, https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models  \n",
    "[4] BGO, CNN with Keras, https://www.kaggle.com/bugraokcu/cnn-with-keras    \n",
    "[5] NAIN, EagerFMINST, https://www.kaggle.com/aakashnain/eagerfmnist  \n",
    "[6] Why Dropounts prevent overfitting in Deep Neural Networks, https://medium.com/@vivek.yadav/why-dropouts-prevent-overfitting-in-deep-neural-networks-937e2543a701  \n",
    "[7] Dropout: A Simple Way to Prevent Neural Networks from Overfitting, https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
